import os
import torch
import cv2
import torchvision.transforms as transforms
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed

# üìÇ Êñá‰ª∂Ë∑ØÂæÑ
video_dir = "/mnt/public/wangsiyuan/HunyuanVideo_efficiency/video_data/video_data_5000"
output_video_dir = "/mnt/public/wangsiyuan/HunyuanVideo_efficiency/video_data/video_data_5000_240p"
output_tensor_dir = "/mnt/public/wangsiyuan/HunyuanVideo_efficiency/video_data/video_data_5000_240p_tensor"

# Á°Æ‰øùËæìÂá∫ÁõÆÂΩïÂ≠òÂú®
os.makedirs(output_video_dir, exist_ok=True)
os.makedirs(output_tensor_dir, exist_ok=True)

# Ëé∑ÂèñÊâÄÊúâ MP4 Êñá‰ª∂
video_files = [f for f in os.listdir(video_dir) if f.endswith(".mp4")]

# Á∫øÁ®ãÊï∞ÔºàÊ†πÊçÆ CPU Ê†∏ÂøÉÊï∞Ë∞ÉÊï¥Ôºâ
NUM_THREADS = 50

# ÁªüËÆ°Ë∑≥ËøáÁöÑÊñá‰ª∂Êï∞
skipped_count = 0

# È¢ÑÂ§ÑÁêÜËΩ¨Êç¢
transform = transforms.ToTensor()

def resize_video(input_path, output_path, target_height=240):
    """ Â∞ÜËßÜÈ¢ëË∞ÉÊï¥‰∏∫ 240p Âπ∂Â≠òÂÇ® """
    cap = cv2.VideoCapture(input_path)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # ËæìÂá∫ MP4 Ê†ºÂºè
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # ‰ªÖË∞ÉÊï¥Â§ß‰∫é target_height ÁöÑËßÜÈ¢ë
    if height > target_height:
        new_width = int(width * (target_height / height))  # ÊåâÊØî‰æãËÆ°ÁÆóÊñ∞ÂÆΩÂ∫¶
        out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, target_height))

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            frame_resized = cv2.resize(frame, (new_width, target_height))  # Ë∞ÉÊï¥ÂàÜËæ®Áéá
            out.write(frame_resized)

        cap.release()
        out.release()
        return True
    else:
        cap.release()
        return False

def video_to_tensor(video_path):
    """ ËØªÂèñ 240p ËßÜÈ¢ëÂπ∂ËΩ¨Êç¢‰∏∫ TensorÔºåÊï∞ÂÄºËåÉÂõ¥Êò†Â∞ÑËá≥ [-1, 1] """
    cap = cv2.VideoCapture(video_path)
    frames = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # OpenCV ËØªÂèñÁöÑÊòØ BGRÔºåÈúÄË¶ÅËΩ¨Êç¢‰∏∫ RGB
        tensor_frame = transform(frame)  # [0,255] ‚Üí [0,1]Ôºå(H, W, C) ‚Üí (C, H, W)
        frames.append(tensor_frame)

    cap.release()

    if len(frames) == 0:
        return None  # Â§ÑÁêÜÁ©∫ËßÜÈ¢ëÊÉÖÂÜµ

    video_tensor = torch.stack(frames)  # (T, C, H, W)
    video_tensor = video_tensor.permute(1, 0, 2, 3)  # (T, C, H, W) ‚Üí (C, T, H, W)
    
    # Êò†Â∞ÑÂà∞ [-1, 1]
    video_tensor = 2 * video_tensor - 1  # [0,1] ‚Üí [-1,1]
    
    return video_tensor

def process_video(video_file):
    """ Â§ÑÁêÜÂçï‰∏™ËßÜÈ¢ëÊñá‰ª∂ÔºöË∞ÉÊï¥Â∞∫ÂØ∏ + ËΩ¨Êç¢‰∏∫ Tensor """
    video_path = os.path.join(video_dir, video_file)
    resized_video_path = os.path.join(output_video_dir, video_file)
    tensor_path = os.path.join(output_tensor_dir, video_file.replace(".mp4", ".pt"))

    # ËØªÂèñËßÜÈ¢ëÈ´òÂ∫¶
    cap = cv2.VideoCapture(video_path)
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()

    if height > 240:
        success = resize_video(video_path, resized_video_path, target_height=240)

        if success:
            video_tensor = video_to_tensor(resized_video_path)
            if video_tensor is not None:
                torch.save(video_tensor, tensor_path)
                return f"‚úÖ {video_file} | shape: {video_tensor.shape}, dtype: {video_tensor.dtype}, range ~ [-1,1]"
            else:
                return f"‚ö†Ô∏è Skipping empty video: {video_file}"
        else:
            return f"‚ùå Failed to resize: {video_file}"
    else:
        return f"üîπ Skipping video (<= 240p): {video_file}"

# ‰ΩøÁî®Â§öÁ∫øÁ®ãÂπ∂Ë°åÂ§ÑÁêÜËßÜÈ¢ë
with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:
    futures = {executor.submit(process_video, video): video for video in video_files}

    for future in tqdm(as_completed(futures), total=len(video_files), desc="Processing Videos"):
        tqdm.write(future.result())

print("‚úÖ ÊâÄÊúâËßÜÈ¢ëÂ§ÑÁêÜÂÆåÊàêÔºÅ")
