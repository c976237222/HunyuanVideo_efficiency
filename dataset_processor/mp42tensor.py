import os
import torch
import cv2
import torchvision.transforms as transforms
from tqdm import tqdm  # å¼•å…¥ tqdm è¿›åº¦æ¡åº“

# ğŸ“‚ æ–‡ä»¶è·¯å¾„
video_dir = "/mnt/public/wangsiyuan/HunyuanVideo_efficiency/video_data/video_data_100"
output_video_dir = "/mnt/public/wangsiyuan/HunyuanVideo_efficiency/video_data/video_data_100_240p"
output_tensor_dir = "/mnt/public/wangsiyuan/HunyuanVideo_efficiency/video_data/video_data_100_240p_tensor"

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(output_video_dir, exist_ok=True)
os.makedirs(output_tensor_dir, exist_ok=True)

# è·å–æ‰€æœ‰ MP4 æ–‡ä»¶
video_files = [f for f in os.listdir(video_dir) if f.endswith(".mp4")]

# ç»Ÿè®¡è·³è¿‡çš„æ–‡ä»¶æ•°
skipped_count = 0

# é¢„å¤„ç†è½¬æ¢ï¼ˆåªè½¬æ¢ä¸º Tensorï¼Œä¸è°ƒæ•´å¤§å°ï¼‰
# transforms.ToTensor() ä¼šæŠŠåƒç´ å€¼ä» [0,255] ç¼©æ”¾åˆ° [0,1]
transform = transforms.ToTensor()

def resize_video(input_path, output_path, target_height=240):
    """ å°†è§†é¢‘è°ƒæ•´ä¸º 240p å¹¶å­˜å‚¨ """
    cap = cv2.VideoCapture(input_path)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # è¾“å‡º MP4 æ ¼å¼
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    print(f"fps: {fps}, width: {width}, height: {height}")
    # ä»…è°ƒæ•´å¤§äº target_height çš„è§†é¢‘
    if height > target_height:
        new_width = int(width * (target_height / height))  # æŒ‰æ¯”ä¾‹è®¡ç®—æ–°å®½åº¦
        out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, target_height))

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            frame_resized = cv2.resize(frame, (new_width, target_height))  # è°ƒæ•´åˆ†è¾¨ç‡
            out.write(frame_resized)

        cap.release()
        out.release()
        return True
    else:
        cap.release()
        return False

def video_to_tensor(video_path):
    """ è¯»å– 240p è§†é¢‘å¹¶è½¬æ¢ä¸º Tensorï¼Œæ•°å€¼èŒƒå›´æ˜ å°„è‡³ [-1, 1] """
    cap = cv2.VideoCapture(video_path)
    frames = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # OpenCV è¯»å–çš„æ˜¯ BGRï¼Œéœ€è¦è½¬æ¢ä¸º RGB
        # [0,255] â†’ [0,1]
        tensor_frame = transform(frame)  # (H, W, C) â†’ (C, H, W)
        frames.append(tensor_frame)

    cap.release()

    if len(frames) == 0:
        return None  # å¤„ç†ç©ºè§†é¢‘æƒ…å†µ

    video_tensor = torch.stack(frames)  # (T, C, H, W)

    # è°ƒæ•´ä¸º (C, T, H, W)
    video_tensor = video_tensor.permute(1, 0, 2, 3)  # å°†ç»´åº¦ä» (T, C, H, W) è°ƒæ•´ä¸º (C, T, H, W)
    
    # æ˜ å°„åˆ° [-1, 1]
    video_tensor = 2 * video_tensor - 1  # [0,1] â†’ [-1,1]
    
    return video_tensor

# éå†æ‰€æœ‰è§†é¢‘æ–‡ä»¶ï¼Œå¹¶åŠ å…¥ tqdm è¿›åº¦æ¡
for video_file in tqdm(video_files, desc="Processing Videos", unit="file"):
    video_path = os.path.join(video_dir, video_file)
    resized_video_path = os.path.join(output_video_dir, video_file)
    tensor_path = os.path.join(output_tensor_dir, video_file.replace(".mp4", ".pt"))

    # è¯»å–è§†é¢‘é«˜åº¦
    cap = cv2.VideoCapture(video_path)
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()

    # ä»…è°ƒæ•´å¤§äº 240p çš„è§†é¢‘
    if height > 240:
        tqdm.write(f"Resizing: {video_file} (Original height: {height} â†’ 240p)")
        success = resize_video(video_path, resized_video_path, target_height=240)

        if success:
            # è¯»å–è°ƒæ•´åçš„è§†é¢‘å¹¶è½¬æ¢ä¸º Tensor
            video_tensor = video_to_tensor(resized_video_path)

            if video_tensor is not None:
                torch.save(video_tensor, tensor_path)
                tqdm.write(f"Saved: {tensor_path}, shape: {video_tensor.shape}, dtype: {video_tensor.dtype}, range ~ [-1,1]")
            else:
                tqdm.write(f"Skipping empty video after resizing: {video_file}")
        else:
            tqdm.write(f"Failed to resize: {video_file}")

    else:
        tqdm.write(f"Skipping video (<= 240p): {video_file}")
        skipped_count += 1

print(f"âœ… æ‰€æœ‰è§†é¢‘å¤„ç†å®Œæˆï¼è·³è¿‡äº† {skipped_count} ä¸ªè§†é¢‘")
