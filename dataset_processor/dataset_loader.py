import os
import torch
from torch.utils.data import Dataset, DataLoader

# ğŸ“‚ è®¾ç½®æ•°æ®è·¯å¾„
tensor_dir = "/home/hanling/HunyuanVideo_efficiency/video_data/video_data_100_240p_tensor"

# âœ… è‡ªå®šä¹‰ Dataset
class VideoTensorDataset(Dataset):
    def __init__(self, tensor_dir):
        self.tensor_dir = tensor_dir
        self.tensor_files = [f for f in os.listdir(tensor_dir) if f.endswith(".pt")]
        self.tensor_files.sort()  # ç¡®ä¿åŠ è½½é¡ºåºä¸€è‡´

    def __len__(self):
        return len(self.tensor_files)

    def __getitem__(self, idx):
        tensor_path = os.path.join(self.tensor_dir, self.tensor_files[idx])
        video_tensor = torch.load(tensor_path)  # (T, C, H, W)

        return video_tensor  # å¯æŒ‰éœ€æ±‚è¿”å› (video_tensor, self.tensor_files[idx])

# âœ… åˆ›å»º DataLoader
batch_size = 4  # æ ¹æ®æ˜¾å­˜è°ƒæ•´
shuffle = True  # æ˜¯å¦éšæœºæ‰“ä¹±æ•°æ®
num_workers = 4  # é€‚ç”¨äºå¤šçº¿ç¨‹åŠ è½½

dataset = VideoTensorDataset(tensor_dir)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)

# âœ… æµ‹è¯• DataLoader
for batch in dataloader:
    print(f"Batch Shape: {batch.shape}")  # (B, T, C, H, W)
    break  # åªæ‰“å°ä¸€ä¸ª batch
