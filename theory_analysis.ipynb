{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import os,sys\n",
    "import torchvision.transforms as transforms\n",
    "# os.environ[\"https_proxy\"]=\"10.10.20.100:1089\"\n",
    "# os.environ[\"https_proxy\"]=\"127.0.0.1:7890\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "sys.path.append('..')\n",
    "sys.path.append('.')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD VAE\n",
    "\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "from hyvideo.utils.file_utils import save_videos_grid\n",
    "from hyvideo.config import parse_args\n",
    "from hyvideo.inference import HunyuanVideoSampler\n",
    "from hyvideo.vae.autoencoder_kl_causal_3d import AutoencoderKLCausal3D\n",
    "import hyvideo.config\n",
    "print(hyvideo.config.__file__)\n",
    "from hyvideo.config import *\n",
    "string_args=\"\"\"--video-size 720 1280 --video-length 129 --infer-steps 50 --prompt cat. --flow-reverse --use-cpu-offload --save-path ./results\"\"\"\n",
    "string_args=string_args.split(\" \")\n",
    "print(string_args)\n",
    "\n",
    "def parse_args_with_string(string_args,namespace=None):\n",
    "    parser = argparse.ArgumentParser(description=\"HunyuanVideo inference script\")\n",
    "\n",
    "    parser = add_network_args(parser)\n",
    "    parser = add_extra_models_args(parser)\n",
    "    parser = add_denoise_schedule_args(parser)\n",
    "    parser = add_inference_args(parser)\n",
    "    parser = add_parallel_args(parser)\n",
    "\n",
    "    args = parser.parse_args(string_args,namespace=namespace)\n",
    "    args = sanity_check_args(args)\n",
    "\n",
    "    return args\n",
    "\n",
    "args = parse_args_with_string(string_args=string_args)\n",
    "print(args)\n",
    "\n",
    "from hyvideo.modules import load_model\n",
    "from hyvideo.vae import load_vae\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "vae, _, s_ratio, t_ratio = load_vae(\n",
    "            args.vae,\n",
    "            args.vae_precision,\n",
    "            logger=logger,\n",
    "            device=device,\n",
    "        )\n",
    "vae:AutoencoderKLCausal3D\n",
    "vae.enable_tiling()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 读取视频文件\n",
    "video_path = \"processed_240p_videos/dance2.mp4\"  # 替换为你的视频文件路径\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 获取fps\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 存储视频帧的亮度值\n",
    "frames = []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # 将帧转换为灰度图并获取亮度值\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frames.append(gray_frame)  # 存储每帧的平均亮度\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# 将帧转换为 numpy 数组\n",
    "signal = np.array(frames)\n",
    "\n",
    "signal=signal.reshape(signal.shape[0],-1)\n",
    "\n",
    "print(signal.shape)\n",
    "\n",
    "# 进行离散傅里叶变换\n",
    "frequencies = np.fft.fft(signal,axis=0)\n",
    "frequencies_magnitude = np.abs(frequencies).mean(axis=1)\n",
    "\n",
    "fft_freq = np.fft.fftfreq(len(signal), 1/fps)\n",
    "\n",
    "# 去除等于0的\n",
    "frequencies_magnitude = frequencies_magnitude[1:]\n",
    "fft_freq = fft_freq[1:]\n",
    "\n",
    "# 频谱图\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.abs(fft_freq),frequencies_magnitude,'x')\n",
    "plt.title('Frequency Spectrum of Original Video')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def read_yuv_file(file_path, width, height, resize_width,resize_height):\n",
    "    # 计算YUV文件的大小\n",
    "    frame_size = width * height\n",
    "    y_size = frame_size\n",
    "    u_size = frame_size // 4\n",
    "    v_size = frame_size // 4\n",
    "    frames=[]\n",
    "    with open(file_path, 'rb') as f:\n",
    "        while True:\n",
    "            # f.read(0)\n",
    "            y = f.read(y_size)\n",
    "            v = f.read(v_size)\n",
    "            u = f.read(u_size)\n",
    "\n",
    "            if not y or not u or not v:\n",
    "                break  # 文件结束\n",
    "\n",
    "            # 将字节数据转换为numpy数组\n",
    "            Y = np.frombuffer(y, dtype=np.uint8).reshape((height, width))\n",
    "            U = np.frombuffer(u, dtype=np.uint8).reshape((height // 2, width // 2))\n",
    "            V = np.frombuffer(v, dtype=np.uint8).reshape((height // 2, width // 2))\n",
    "\n",
    "            # 上采样U和V分量\n",
    "            U_up = cv2.resize(U, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "            V_up = cv2.resize(V, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # 合并YUV分量为BGR格式\n",
    "            yuv = cv2.merge((Y, U_up, V_up))\n",
    "            bgr = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)\n",
    "            bgr = cv2.resize(bgr,(resize_width,resize_height))\n",
    "            frames.append(bgr)\n",
    "    return frames\n",
    "\n",
    "# 示例调用\n",
    "# path=\"/mnt/public/wangsiyuan/k8bfn0qsj9fs1rwnc2x75z6t7/BVI-HFR/60hz/\"\n",
    "\n",
    "\n",
    "# # 读取视频文件\n",
    "# video_path = path+\"flowers-60fps-360-1920x1080.yuv\"  # 替换为你的视频文件路径\n",
    "# read_yuv_file(video_path, width=1920, height=1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/mnt/public/wangsiyuan/k8bfn0qsj9fs1rwnc2x75z6t7/BVI-HFR/60hz/\"\n",
    "fps = 60\n",
    "datas_original_x=[]\n",
    "datas_original_y=[]\n",
    "datas_latent_x=[]\n",
    "datas_latent_y=[]\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".yuv\"):\n",
    "        print(filename)\n",
    "        video_path = path+filename  # 替换为你的视频文件路径\n",
    "        raw_frames=read_yuv_file(video_path, width=1920, height=1080,resize_width=1920//4,resize_height=1080//4)\n",
    "        # 存储视频帧的亮度值\n",
    "        frames=[]\n",
    "        tensor_frames=[]\n",
    "        for frame in raw_frames:\n",
    "            # 将帧转换为灰度图并获取亮度值\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frames.append(gray_frame)  # 存储每帧的平均亮度\n",
    "            tensor_frame = transforms.ToTensor()(frame)\n",
    "            tensor_frames.append(tensor_frame)\n",
    "\n",
    "        # 将帧转换为 numpy 数组\n",
    "        signal = np.array(frames)\n",
    "\n",
    "        signal=signal.reshape(signal.shape[0],-1)\n",
    "\n",
    "        print(signal.shape)\n",
    "\n",
    "        # 进行离散傅里叶变换\n",
    "        frequencies = np.fft.fft(signal,axis=0)\n",
    "        frequencies_magnitude = np.abs(frequencies).mean(axis=1)\n",
    "\n",
    "        fft_freq = np.fft.fftfreq(len(signal), 1/fps)\n",
    "\n",
    "        # 去除等于0的\n",
    "        frequencies_magnitude = frequencies_magnitude[1:]\n",
    "        fft_freq = fft_freq[1:]\n",
    "\n",
    "        datas_original_x.append(np.abs(fft_freq))\n",
    "        datas_original_y.append(frequencies_magnitude)\n",
    "\n",
    "        # 频谱图\n",
    "        # plt.figure(figsize=(12, 5))\n",
    "        # plt.title(filename.split('-')[0])\n",
    "\n",
    "        # plt.subplot(1,2,1)\n",
    "        # plt.plot(np.abs(fft_freq),frequencies_magnitude,'x')\n",
    "        # plt.title('Frequency Spectrum of Original Video')\n",
    "        # plt.xlabel('Frequency')\n",
    "        # plt.ylabel('Magnitude')\n",
    "        # plt.grid()\n",
    "\n",
    "        video_tensor = torch.stack(tensor_frames)          # (T, C, H, W)\n",
    "        video_tensor = video_tensor.permute(1, 0, 2, 3)  # (C, T, H, W)\n",
    "        video_tensor = 2 * video_tensor - 1         # [-1, 1]范围\n",
    "\n",
    "        x=video_tensor.unsqueeze(0).half().cuda()\n",
    "        y=vae.encode(x)\n",
    "\n",
    "        signal = y.latent_dist.mean.permute(0,1,3,4,2)\n",
    "        signal = signal.reshape(-1,signal.shape[-1]).cpu().numpy()\n",
    "\n",
    "        print(signal.shape)\n",
    "\n",
    "        # 进行离散傅里叶变换\n",
    "        frequencies = np.fft.fft(signal,axis=1)\n",
    "        frequencies_magnitude = np.abs(frequencies).mean(axis=0)\n",
    "        frequencies_magnitude = frequencies_magnitude[1:]\n",
    "\n",
    "        fft_freq = np.fft.fftfreq(signal.shape[1], 4/fps)\n",
    "        fft_freq = fft_freq[1:]\n",
    "\n",
    "        datas_latent_x.append(np.abs(fft_freq))\n",
    "        datas_latent_y.append(frequencies_magnitude)\n",
    "\n",
    "        # 频谱图\n",
    "        # plt.subplot(1,2,2)\n",
    "        # plt.plot(np.abs(fft_freq),frequencies_magnitude,'x')\n",
    "        # plt.title('Frequency Spectrum of Latent Space')\n",
    "        # plt.xlabel('Frequency')\n",
    "        # plt.ylabel('Magnitude')\n",
    "        # plt.grid()\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.subplot(2,1,1)\n",
    "        \n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".yuv\"):\n",
    "        name=filename.split('-')[0]\n",
    "        if cnt%3==1:\n",
    "            plt.plot(datas_original_x[cnt],datas_original_y[cnt],'-',label=name)\n",
    "        cnt+=1\n",
    "plt.title('Frequency Spectrum of Original Video')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.ylim(0,2000)\n",
    "plt.xlim(0,30)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "\n",
    "cnt=0\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".yuv\"):\n",
    "        name=filename.split('-')[0]\n",
    "        if cnt%3==1:\n",
    "            plt.plot(datas_latent_x[cnt],datas_latent_y[cnt],'-',label=name)\n",
    "        cnt+=1\n",
    "plt.title('Frequency Spectrum of Latent Space (HunyuanVideo VAE)')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.ylim(1,20)\n",
    "plt.xlim(0.1,7.5)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('output/frequency_analyse.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/mnt/public/wangsiyuan/k8bfn0qsj9fs1rwnc2x75z6t7/BVI-HFR/60hz/\"\n",
    "fps = 60\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".yuv\"):\n",
    "        print(filename)\n",
    "        video_path = path+filename  # 替换为你的视频文件路径\n",
    "        raw_frames=read_yuv_file(video_path, width=1920, height=1080,resize_width=1920//2,resize_height=1080//2)\n",
    "        # 存储视频帧的亮度值\n",
    "        frames=[]\n",
    "        tensor_frames=[]\n",
    "        for frame in raw_frames:\n",
    "            # 将帧转换为灰度图并获取亮度值\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frames.append(gray_frame)  # 存储每帧的平均亮度\n",
    "            tensor_frame = transforms.ToTensor()(frame)\n",
    "            tensor_frames.append(tensor_frame)\n",
    "\n",
    "        # 将帧转换为 numpy 数组\n",
    "        signal = np.array(frames)\n",
    "\n",
    "        signal=signal.reshape(signal.shape[0],-1)\n",
    "\n",
    "        print(signal.shape)\n",
    "\n",
    "        # 进行离散傅里叶变换\n",
    "        frequencies = np.fft.fft(signal,axis=0)\n",
    "        frequencies_magnitude = np.abs(frequencies).mean(axis=1)\n",
    "\n",
    "        fft_freq = np.fft.fftfreq(len(signal), 1/fps)\n",
    "\n",
    "        # 去除等于0的\n",
    "        frequencies_magnitude = frequencies_magnitude[1:]\n",
    "        fft_freq = fft_freq[1:]\n",
    "\n",
    "        # 频谱图\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.title(filename.split('-')[0])\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(np.abs(fft_freq),frequencies_magnitude,'x')\n",
    "        plt.title('Frequency Spectrum of Original Video')\n",
    "        plt.xlabel('Frequency')\n",
    "        plt.ylabel('Magnitude')\n",
    "        plt.grid()\n",
    "\n",
    "        video_tensor = torch.stack(tensor_frames)          # (T, C, H, W)\n",
    "        video_tensor = video_tensor.permute(1, 0, 2, 3)  # (C, T, H, W)\n",
    "        video_tensor = 2 * video_tensor - 1         # [-1, 1]范围\n",
    "\n",
    "        x=video_tensor.unsqueeze(0).half().cuda()\n",
    "        y=vae.encode(x)\n",
    "\n",
    "        signal = y.latent_dist.mean.permute(0,1,3,4,2)\n",
    "        signal = signal.reshape(-1,signal.shape[-1]).cpu().numpy()\n",
    "\n",
    "        print(signal.shape)\n",
    "\n",
    "        # 进行离散傅里叶变换\n",
    "        frequencies = np.fft.fft(signal,axis=1)\n",
    "        frequencies_magnitude = np.abs(frequencies).mean(axis=0)\n",
    "        frequencies_magnitude = frequencies_magnitude[1:]\n",
    "\n",
    "        fft_freq = np.fft.fftfreq(signal.shape[1], 4/fps)\n",
    "        fft_freq = fft_freq[1:]\n",
    "\n",
    "        # 频谱图\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(np.abs(fft_freq),frequencies_magnitude,'x')\n",
    "        plt.title('Frequency Spectrum of Latent Space')\n",
    "        plt.xlabel('Frequency')\n",
    "        plt.ylabel('Magnitude')\n",
    "        plt.grid()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HunyuanVideo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
